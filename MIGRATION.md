# Migration Plan: SQLite ‚Üí PostgreSQL + node-cron ‚Üí BullMQ

**Status:** üöß In Progress
**Started:** 2025-11-29
**Current Phase:** Partie I - Step 3

---

## Partie I : Migration SQLite ‚Üí PostgreSQL

### ‚úÖ 0. Plan cr√©√© et stock√©
- [x] Plan d√©taill√© document√© dans MIGRATION.md

### ‚úÖ 1. Pr√©paration et connexion aux bases PostgreSQL

**1.1. Installer les d√©pendances PostgreSQL**
- [x] Ajouter `pg` (driver PostgreSQL Node.js)
- [x] Ajouter `drizzle-orm`
- [x] Ajouter `@types/pg`
- [x] Garder `better-sqlite3` en dependencies (utilis√© pour dev local)

**1.2. Tester la connexion aux bases existantes**
- [x] Se connecter √† `gs-stream-db-staging` (kyzl60xwk9xrpj9g)
- [x] Se connecter √† `gs-stream-db` (d2gznoqmkl70pkm8)
- [x] Lister les tables existantes pour comprendre ce que NATS utilise
  - Tables NATS trouv√©es : api_keys, digest_configs, events, event_access_rules, webhook_subscriptions, etc.
  - ‚úÖ Aucune table `digest_*` n'existe, on peut cr√©er nos tables sans conflit
- [x] V√©rifier qu'on a les bons acc√®s

### ‚úÖ 2. Cr√©ation de l'utilisateur d√©di√©

**2.1. Cr√©er l'utilisateur `digestuser` sur staging**
- [x] Utilisateur cr√©√© avec r√¥le `writer` via `flyctl mpg users create`
- [x] Username: `digestuser` (note: underscores not allowed in Fly.io MPG usernames)

**2.2. Cr√©er l'utilisateur `digestuser` sur production**
- [x] Utilisateur cr√©√© avec r√¥le `writer` via `flyctl mpg users create`
- [x] Username: `digestuser`

**2.3. Stocker les credentials de mani√®re s√©curis√©e**
- [ ] Note: Fly.io MPG g√®re les passwords automatiquement et les expose via les connexions internes
- [ ] Les credentials seront configur√©s via les secrets Fly.io pour `DATABASE_URL`
- [ ] Format : `postgresql://digestuser:<auto-generated-password>@pgdb-{cluster-id}-pgbouncer.pgdb-{cluster-id}.svc:5432/fly-db`

### ‚úÖ 3. Migration du sch√©ma de base de donn√©es

**3.1. Mettre √† jour les sch√©mas Drizzle avec pr√©fixe `digest_`**

Modifier `/packages/database/src/schema/`:
- [x] `digests.ts` ‚Üí tables `digest_digests`, `digest_templates`, `digest_runs`, `digest_email_logs`, `digest_api_keys`, `digest_webhook_events`
- [x] `templates.ts` ‚Üí table `digest_email_templates`
- [x] `admin.ts` ‚Üí tables `digest_applications`, `digest_event_types`

**3.2. Adapter le client de connexion**

Modifier `/packages/database/src/client.ts`:
- [x] D√©tecter l'environnement (SQLite dev, PostgreSQL staging/prod)
- [x] Utiliser `drizzle(postgres, { schema })` pour PostgreSQL
- [x] Garder `drizzle(sqlite, { schema })` pour dev local
- [x] Variable d'environnement `DATABASE_URL` vs `DATABASE_PATH`
- [x] Pool PostgreSQL configur√© (max 20 connexions, 30s idle timeout)

**3.3. Cr√©er les migrations Drizzle**
```bash
npm run db:generate:pg
```
- [x] G√©n√©rer les migrations SQL pour PostgreSQL
- [x] V√©rifier que les migrations contiennent bien le pr√©fixe `digest_`
- [x] Migrations g√©n√©r√©es dans `/packages/database/src/migrations-pg/0000_little_riptide.sql`
- [x] 9 tables cr√©√©es avec pr√©fixe `digest_`: digests, templates, runs, email_logs, api_keys, webhook_events, email_templates, applications, event_types

**3.4. Appliquer les migrations**

- [x] Sur staging via flyctl mpg connect (9 tables cr√©√©es avec succ√®s)
- [x] Sur production via flyctl mpg connect (9 tables cr√©√©es avec succ√®s)
- [x] Tables v√©rifi√©es : digest_applications, digest_event_types, digest_api_keys, digest_runs, digest_templates, digest_digests, digest_email_logs, digest_webhook_events, digest_email_templates

### ‚úÖ 4. Configuration des permissions PostgreSQL

**4.1. Accorder les permissions sur les tables**
```sql
GRANT CONNECT ON DATABASE "fly-db" TO digest_user;
GRANT USAGE ON SCHEMA public TO digest_user;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO digest_user;
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO digest_user;

-- Permissions futures (pour les nouvelles tables)
ALTER DEFAULT PRIVILEGES IN SCHEMA public
GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO digest_user;
```

**4.2. V√©rifier l'isolation**
- [x] Permissions accord√©es sur les 9 tables digest_* (staging + production)
- [x] digestuser a les permissions SELECT, INSERT, UPDATE, DELETE (arwd)
- [x] V√©rification via `\z digest_*` montre les bonnes permissions

### ‚úÖ 5. Migration des donn√©es existantes

**Note:** Les donn√©es SQLite locales sont uniquement pour le d√©veloppement local (2 digests, 1 template, 101 runs de test). Les environnements staging et production d√©marreront avec des tables vides, ce qui est appropri√© pour une nouvelle infrastructure PostgreSQL.

**5.1. Exporter les donn√©es depuis SQLite (staging)**
- [ ] Cr√©er script `scripts/migrate-sqlite-to-postgres.js`
- [ ] Lire toutes les donn√©es depuis `data/digest.db`
- [ ] Ins√©rer dans PostgreSQL staging via `DATABASE_URL`
- [ ] G√©rer les transactions
- [ ] V√©rifier l'int√©grit√© (count des rows)

**5.2. Valider les donn√©es migr√©es**
- [ ] Comparer le nombre de rows SQLite vs PostgreSQL
- [ ] V√©rifier quelques digests manuellement
- [ ] Tester les requ√™tes critiques

**5.3. Migration production (apr√®s validation staging)**
- [ ] Faire un backup PostgreSQL avant
- [ ] Migrer les donn√©es de production
- [ ] Valider les donn√©es

### 6. Mise √† jour du code applicatif

**6.1. Mettre √† jour le backend**
- [ ] Variables d'environnement : `DATABASE_URL` (PostgreSQL) vs `DATABASE_PATH` (SQLite)
- [ ] Tester les queries Drizzle
- [ ] V√©rifier les types TypeScript

**6.2. Mise √† jour de la configuration Fly.io**

- [ ] Ajouter secrets DATABASE_URL pour staging
- [ ] Ajouter secrets DATABASE_URL pour production
- [ ] Supprimer la section `[[mounts]]` de `fly.toml`

**6.3. D√©ploiement**
- [ ] D√©ployer staging
- [ ] D√©ployer production

### 7. Tests et validation

**7.1. Tests locaux**
- [ ] Garder SQLite en dev local
- [ ] Tester toutes les op√©rations CRUD

**7.2. Tests staging**
- [ ] V√©rifier que les digests se cr√©ent/modifient/suppriment correctement
- [ ] V√©rifier l'ex√©cution des jobs
- [ ] V√©rifier l'envoi d'emails

**7.3. Tests production**
- [ ] D√©ployer sur production apr√®s validation staging
- [ ] Monitoring Axiom pour d√©tecter les erreurs
- [ ] Rollback plan si probl√®mes

---

## Partie II : Migration node-cron ‚Üí BullMQ

### 1. Installation et configuration Redis

**1.1. Cr√©er les instances Redis manag√©es sur Fly.io**

Staging + Dev (partag√©):
```bash
flyctl redis create gs-digest-redis-dev-staging \
  --org grafmaker \
  --region cdg \
  --plan free
```

Production (d√©di√©):
```bash
flyctl redis create gs-digest-redis-prod \
  --org grafmaker \
  --region cdg \
  --plan hobby-1024
```

**1.2. R√©cup√©rer les URLs de connexion Redis**
- [ ] R√©cup√©rer URL staging
- [ ] R√©cup√©rer URL production

**1.3. Configurer les secrets Fly.io**
- [ ] Ajouter REDIS_URL staging
- [ ] Ajouter REDIS_URL production

### 2. Installation des d√©pendances BullMQ

- [ ] `npm install bullmq ioredis --workspace=@gs-digest/backend`
- [ ] `npm install -D @types/ioredis --workspace=@gs-digest/backend`

### 3. Mise en place de BullMQ

**3.1. Cr√©er la configuration Redis**
- [ ] Cr√©er `/apps/backend/src/config/redis.ts`

**3.2. Cr√©er la queue BullMQ**
- [ ] Cr√©er `/apps/backend/src/queues/digest-queue.ts`

**3.3. Cr√©er le worker BullMQ**
- [ ] Cr√©er `/apps/backend/src/workers/digest-worker.ts`

### 4. Cr√©er le scheduler BullMQ (remplace node-cron)

**4.1. Cr√©er le service de scheduling**
- [ ] Cr√©er `/apps/backend/src/services/digest-scheduler.ts`
- [ ] Impl√©menter syncRepeatableJobs()
- [ ] Impl√©menter triggerManualRun()
- [ ] Impl√©menter triggerTestRun()

### 5. Int√©gration dans l'application

**5.1. Mettre √† jour `/apps/backend/src/index.ts`**
- [ ] Importer DigestScheduler
- [ ] Importer digestWorker
- [ ] D√©marrer le worker et scheduler
- [ ] G√©rer le graceful shutdown

**5.2. Mettre √† jour les endpoints API**
- [ ] Modifier `/apps/backend/src/routes/digests.ts`
- [ ] Endpoint POST `/digests/:id/run` (manual)
- [ ] Endpoint POST `/digests/:id/test` (test)

### 6. Supprimer l'ancien syst√®me node-cron

**6.1. Retirer les d√©pendances**
- [ ] `npm uninstall node-cron @types/node-cron --workspace=@gs-digest/backend`
- [ ] `npm uninstall piscina --workspace=@gs-digest/backend`

**6.2. Supprimer les fichiers obsol√®tes**
- [ ] Supprimer `/apps/backend/src/services/scheduler.ts` (ancien)
- [ ] Supprimer `/apps/backend/src/jobs/process-digest-wrapper.mjs`

**6.3. Nettoyer les r√©f√©rences**
- [ ] Retirer les imports de `node-cron` et `Piscina`
- [ ] V√©rifier qu'aucun code ne r√©f√©rence l'ancien scheduler

### 7. Dashboard BullMQ (optionnel)

**7.1. Ajouter Bull Board pour monitoring**
- [ ] `npm install @bull-board/express @bull-board/api --workspace=@gs-digest/backend`

**7.2. Cr√©er l'interface de monitoring**
- [ ] Ajouter Bull Board dans `/apps/backend/src/index.ts`

### 8. Tests et validation BullMQ

**8.1. Tests locaux**
- [ ] Installer Redis local (Docker)
- [ ] Tester l'ajout de jobs
- [ ] Tester l'ex√©cution des jobs
- [ ] Tester les retries en cas d'√©chec

**8.2. Tests staging**
- [ ] D√©ployer sur staging
- [ ] V√©rifier que les jobs s'ex√©cutent selon le schedule
- [ ] Tester les runs manuels et tests
- [ ] Monitorer les erreurs

**8.3. Tests de charge (optionnel)**
- [ ] Cr√©er 100+ digests avec des schedules rapproch√©s
- [ ] V√©rifier que BullMQ g√®re bien la concurrence

### 9. Monitoring et observabilit√©

**9.1. Ajouter des m√©triques**
- [ ] Nombre de jobs en attente
- [ ] Nombre de jobs completed/failed
- [ ] Temps d'ex√©cution moyen
- [ ] Taux de succ√®s

**9.2. Int√©grer avec Axiom**
- [ ] Logger tous les √©v√©nements BullMQ importants
- [ ] Cr√©er des dashboards

**9.3. Alertes**
- [ ] Alerter si trop de jobs √©chouent
- [ ] Alerter si la queue Redis est pleine
- [ ] Alerter si le worker est down

---

## Timeline estim√©e

**Partie I (SQLite ‚Üí PostgreSQL)** : 2-3 jours
- Jour 1 : Setup, migrations, tests locaux
- Jour 2 : Migration staging, validation
- Jour 3 : Migration production

**Partie II (node-cron ‚Üí BullMQ)** : 3-4 jours
- Jour 1-2 : Setup Redis, impl√©mentation BullMQ
- Jour 3 : Tests et validation
- Jour 4 : Monitoring et optimisation

**Total : 5-7 jours de d√©veloppement**

---

## Notes et d√©cisions

### D√©cisions prises
- **Base PostgreSQL** : R√©utiliser les instances existantes `gs-stream-db-staging` et `gs-stream-db`
- **Pr√©fixe tables** : Utiliser `digest_` pour toutes nos tables
- **Utilisateur d√©di√©** : Cr√©er `digest_user` avec permissions restreintes
- **Redis** : Instances manag√©es Fly.io (1 pour dev+staging, 1 pour prod)

### Connexions PostgreSQL
- **Staging**: `gs-stream-db-staging` (kyzl60xwk9xrpj9g)
  - Host: `pgbouncer.kyzl60xwk9xrpj9g.flympg.net`
  - Database: `fly-db`
  - Region: Frankfurt (fra)
  - Plan: Basic (10GB, 1 replica)

- **Production**: `gs-stream-db` (d2gznoqmkl70pkm8)
  - Host: `pgbouncer.d2gznoqmkl70pkm8.flympg.net`
  - Database: `fly-db`
  - Region: Frankfurt (fra)
  - Plan: Basic (10GB, 1 replica)

### Credentials (√† ne pas commiter)
- Staging password: `bvON2p0LTYUcdYFitOncR370`
- Production password: `sno9wgaQbaTG5s3dO6pzCkGS`
